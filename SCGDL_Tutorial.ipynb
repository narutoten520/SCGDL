{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCDGL_new  and SCGDL_Train_new Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## SPGDL_utils.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.neighbors\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "import scipy.sparse as sp\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def Adata2Torch_data(adata): \n",
    "    G_df = adata.uns['Spatial_Net'].copy() \n",
    "    spots = np.array(adata.obs_names) \n",
    "    spots_id_tran = dict(zip(spots, range(spots.shape[0]))) \n",
    "    G_df['Spot1'] = G_df['Spot1'].map(spots_id_tran) \n",
    "    G_df['Spot2'] = G_df['Spot2'].map(spots_id_tran) \n",
    "\n",
    "    G = sp.coo_matrix((np.ones(G_df.shape[0]), (G_df['Spot1'], G_df['Spot2'])), shape=(adata.n_obs, adata.n_obs))\n",
    "    G = G + sp.eye(G.shape[0])\n",
    "\n",
    "    edgeList = np.nonzero(G) \n",
    "    if type(adata.X) == np.ndarray:\n",
    "        data = Data(edge_index=torch.LongTensor(np.array(\n",
    "            [edgeList[0], edgeList[1]])), x=torch.FloatTensor(adata.X))  \n",
    "    else:\n",
    "        data = Data(edge_index=torch.LongTensor(np.array(\n",
    "            [edgeList[0], edgeList[1]])), x=torch.FloatTensor(adata.X.todense()))  \n",
    "    return data\n",
    "\n",
    "def Spatial_Dis_Cal(adata, rad_dis=None, knn_dis=None, model='Radius', verbose=True):\n",
    "    \"\"\"\\\n",
    "    Calculate the spatial neighbor networks, as the distance between two spots.\n",
    "    Parameters\n",
    "    ----------\n",
    "    adata:  AnnData object of scanpy package.\n",
    "    rad_dis:  radius distance when model='Radius' \n",
    "    knn_dis:  The number of nearest neighbors when model='KNN'\n",
    "    model:\n",
    "        The network construction model. When model=='Radius', the spot is connected to spots whose distance is less than rad_dis. \n",
    "        When model=='KNN', the spot is connected to its first knn_dis nearest neighbors.\n",
    "    Returns\n",
    "    -------\n",
    "    The spatial networks are saved in adata.uns['Spatial_Net']\n",
    "    \"\"\"\n",
    "    assert(model in ['Radius', 'KNN']) \n",
    "    if verbose:\n",
    "        print('------Calculating spatial graph...')\n",
    "    coor = pd.DataFrame(adata.obsm['spatial']) \n",
    "    coor.index = adata.obs.index \n",
    "    coor.columns = ['Spatial_X', 'Spatial_Y'] \n",
    "\n",
    "    if model == 'Radius':\n",
    "        nbrs = sklearn.neighbors.NearestNeighbors(radius=rad_dis).fit(coor)\n",
    "        distances, indices = nbrs.radius_neighbors(coor, return_distance=True)\n",
    "        KNN_list = []\n",
    "        for spot in range(indices.shape[0]):\n",
    "            KNN_list.append(pd.DataFrame(zip([spot]*indices[spot].shape[0], indices[spot], distances[spot]))) \n",
    "    \n",
    "    if model == 'KNN':\n",
    "        nbrs = sklearn.neighbors.NearestNeighbors(n_neighbors=knn_dis+1).fit(coor)\n",
    "        distances, indices = nbrs.kneighbors(coor)\n",
    "        KNN_list = []\n",
    "        for spot in range(indices.shape[0]):\n",
    "            KNN_list.append(pd.DataFrame(zip([spot]*indices.shape[1],indices[spot,:], distances[spot,:])))\n",
    "\n",
    "    KNN_df = pd.concat(KNN_list) \n",
    "    KNN_df.columns = ['Spot1', 'Spot2', 'Distance']\n",
    "\n",
    "    Spatial_Net = KNN_df.copy()\n",
    "    Spatial_Net = Spatial_Net.loc[Spatial_Net['Distance']>0,]\n",
    "    id_spot_trans = dict(zip(range(coor.shape[0]), np.array(coor.index), )) \n",
    "    Spatial_Net['Spot1'] = Spatial_Net['Spot1'].map(id_spot_trans) \n",
    "    Spatial_Net['Spot2'] = Spatial_Net['Spot2'].map(id_spot_trans) \n",
    "    if verbose:\n",
    "        print('The graph contains %d edges, %d spots.' %(Spatial_Net.shape[0], adata.n_obs)) \n",
    "        print('%.4f neighbors per spot on average.' %(Spatial_Net.shape[0]/adata.n_obs)) \n",
    "\n",
    "    adata.uns['Spatial_Net'] = Spatial_Net\n",
    "\n",
    "def Spatial_Dis_Draw(adata):\n",
    "    import matplotlib.pyplot as plt\n",
    "    Num_edge = adata.uns['Spatial_Net']['Spot1'].shape[0] \n",
    "    Mean_edge = Num_edge/adata.shape[0] \n",
    "    plot_df = pd.value_counts(pd.value_counts(adata.uns['Spatial_Net']['Spot1'])) \n",
    "    plot_df = plot_df/adata.shape[0]  \n",
    "    fig, ax = plt.subplots(figsize=[4,4],dpi=300)\n",
    "    plt.ylabel('Percentage')\n",
    "    plt.xlabel('Edge Numbers per Spot')\n",
    "    plt.title('Number of Neighbors for Spots (Average=%.2f)'%Mean_edge)\n",
    "    ax.bar(plot_df.index, plot_df,color=\"#aa40fc\",edgecolor=\"#f7b6d2\",linewidth=2)\n",
    "\n",
    "def Cal_Spatial_variable_genes(adata):\n",
    "    import SpatialDE\n",
    "    counts = pd.DataFrame(adata.X, columns=adata.var_names, index=adata.obs_names)\n",
    "    coor = pd.DataFrame(adata.obsm['spatial'], columns=['Spatial_X', 'Spatial_Y'], index=adata.obs_names)\n",
    "    Spatial_var_genes = SpatialDE.run(coor, counts)\n",
    "    Spatial_3000_var_genes = Spatial_var_genes[\"g\"].values[0:3000]\n",
    "    Spatial_3000_var_genes = pd.DataFrame(Spatial_3000_var_genes)\n",
    "    all_genes = counts.columns.to_frame()\n",
    "    for i in range(len(all_genes.values)):\n",
    "        if all_genes.values[i] in Spatial_3000_var_genes.values:\n",
    "            all_genes.values[i] =1\n",
    "        else:\n",
    "            all_genes.values[i] =0\n",
    "    Spatial_highly_genes = all_genes.squeeze()\n",
    "    adata.var[\"Spatial_highly_variable_genes\"] = Spatial_highly_genes.astype(bool)\n",
    "\n",
    "def DGI_loss_Draw(adata):\n",
    "    import matplotlib.pyplot as plt\n",
    "    if \"SCGDL_loss\" not in adata.uns.keys():\n",
    "        raise ValueError(\"Please Train DGI Model using SCGDL_Train function first!\") \n",
    "    Train_loss = adata.uns[\"SCGDL_loss\"]\n",
    "    plt.style.use('default') \n",
    "    plt.plot(Train_loss,label='Training loss',linewidth=2)\n",
    "    plt.xlabel(\"Number of Epochs\")\n",
    "    plt.ylabel(\"Loss of DGI model\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "def BGMM(adata,n_cluster,used_obsm='SCGDL'):\n",
    "    \"\"\"\n",
    "    BayesianGaussianMixture for spatial clustering.\n",
    "    \"\"\"\n",
    "\n",
    "    knowledge = BayesianGaussianMixture(n_components=n_cluster,\n",
    "                                        weight_concentration_prior_type ='dirichlet_process', ##'dirichlet_process' or dirichlet_distribution'\n",
    "                                        weight_concentration_prior = 50).fit(adata.obsm[used_obsm])                                  \n",
    "    # load ground truth for ARI and NMI computation.\n",
    "    Ann_df = pd.read_csv(\"/home/tengliu/Torch_pyG/SCGDL_Upload_Files/data/Human_DLPFC/151676_truth.txt\", sep='\\t', header=None, index_col=0)\n",
    "    Ann_df.columns = ['Ground Truth']\n",
    "    adata.obs['Ground Truth'] = Ann_df.loc[adata.obs_names, 'Ground Truth']\n",
    "\n",
    "    method = \"BayesianGaussianMixture\"\n",
    "    labels = knowledge.predict(adata.obsm[used_obsm])+1\n",
    "    Ann_df.columns = [method] \n",
    "    Ann_df.loc[:,method] = labels \n",
    "    adata.obs[method] = Ann_df.loc[adata.obs_names, method] \n",
    "    adata.obs[method] = adata.obs[method].astype('category') \n",
    "    obs_df = adata.obs.dropna() \n",
    "    ARI = adjusted_rand_score(obs_df[method], obs_df['Ground Truth']) \n",
    "    adata.uns[\"ARI\"] = ARI \n",
    "    return adata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "adata=sc.read('/home/tengliu/Torch_pyG/SCGDL_Upload_Files/data/Human_DLPFC/151676_Anndata.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (4, 4)\n",
    "sc.pl.spatial(adata, img_key=\"hires\", color=[\"Ground Truth\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Spatial_Dis_Cal(adata,rad_dis=150)\n",
    "Spatial_Dis_Draw(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCGDL_Train_new.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm \n",
    "import scipy.sparse as sp\n",
    "\n",
    "from SCGDL import ResGatedGraphmodel\n",
    "from SCGDL_auxiliary import Adata2Torch_data\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.deterministic = True \n",
    "cudnn.benchmark = True \n",
    "import torch.nn.functional as F \n",
    "from torch_geometric.nn import DeepGraphInfomax\n",
    "\n",
    "class my_data():\n",
    "    def __init__(self, x, edge_index, edge_attr):\n",
    "        self.x = x\n",
    "        self.edge_index = edge_index\n",
    "        self.edge_attr = edge_attr\n",
    "\n",
    "def corruption(data): \n",
    "    x = data.x[torch.randperm(data.x.size(0))] \n",
    "    return my_data(x, data.edge_index, data.edge_attr)\n",
    "\n",
    "\n",
    "def SCGDL_Train(adata, \n",
    "                hidden_dims=[128, 128], \n",
    "                num_epochs=1000, \n",
    "                lr=1e-6, \n",
    "                key_added='SCGDL',\n",
    "                gradient_clipping=5., \n",
    "                weight_decay=0.0001, \n",
    "                random_seed=0, save_loss=True):\n",
    "    \"\"\"\\\n",
    "    Training graph attention auto-encoder.\n",
    "    Parameters\n",
    "    ----------\n",
    "    adata: AnnData object of scanpy package.\n",
    "    hidden_dims: The dimension of the encoder.\n",
    "    n_epochs:Number of total epochs for training.\n",
    "    lr: Learning rate for AdamOptimizer.\n",
    "    key_added: The latent embeddings are saved in adata.obsm[key_added].\n",
    "    gradient_clipping: Gradient Clipping. \n",
    "    weight_decay: Weight decay for AdamOptimizer.\n",
    "    save_loss: If True, the training loss is saved in adata.uns['SCGDL_loss'].\n",
    "    save_reconst_exp: If True, the reconstructed expression profiles are saved in adata.layers['SCGDL_ReX'].\n",
    "    device: See torch.device.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    AnnData\n",
    "    \"\"\"\n",
    "    seed=random_seed\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    adata.X = sp.csr_matrix(adata.X)\n",
    "\n",
    "    if \"Spatial_highly_variable_genes\" in adata.var.columns:\n",
    "        adata_Vars =  adata[:, adata.var['Spatial_highly_variable_genes']]\n",
    "        print('Input Size using Spatial_variable_genes: ', adata_Vars.shape)\n",
    "    elif 'highly_variable' in adata.var.columns:\n",
    "        adata_Vars =  adata[:, adata.var['highly_variable']]\n",
    "        print('Input Size using Highly_variable_genes: ', adata_Vars.shape)\n",
    "    else:\n",
    "        adata_Vars = adata\n",
    "        print('Input Size using All genes list: ', adata_Vars.shape) \n",
    "\n",
    "    if 'Spatial_Net' not in adata.uns.keys():\n",
    "        raise ValueError(\"Please Compute Spatial Network using Spatial_Dis_Cal function first!\") \n",
    "\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    data = Adata2Torch_data(adata_Vars) \n",
    "    hidden_dims = [data.x.shape[1]] + hidden_dims \n",
    "  \n",
    "    DGI_model = DeepGraphInfomax(\n",
    "        hidden_channels=hidden_dims[1], \n",
    "        encoder=ResGatedGraphmodel(hidden_dims), \n",
    "        summary=lambda z, *args, **kwargs: torch.sigmoid(z.mean(dim=0)), \n",
    "        corruption=corruption).to(device) \n",
    "    DGI_optimizer = torch.optim.Adam(DGI_model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    data = data.to(device)\n",
    "\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    loss_list = []\n",
    "    for epoch in tqdm(range(1, num_epochs+1)):\n",
    "        DGI_model.train()\n",
    "        DGI_optimizer.zero_grad() \n",
    "        pos_z, neg_z, summary = DGI_model(data=data) \n",
    "        DGI_loss = DGI_model.loss(pos_z, neg_z, summary) \n",
    "        loss_list.append(DGI_loss.item())\n",
    "        DGI_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(DGI_model.parameters(), gradient_clipping) \n",
    "        DGI_optimizer.step()\n",
    "        if ((epoch)%1000) == 0:\n",
    "            print('Epoch: {:03d}, Loss: {:.4f}'.format(epoch, np.mean(loss_list)))\n",
    "    end_time = time.time()\n",
    "    print('Elapsed training time:{:.4f} seconds'.format((end_time-start_time)))\n",
    "\n",
    "    DGI_model.eval()\n",
    "    pos_z, neg_z, summary = DGI_model(data=data) \n",
    "\n",
    "    SCGDL_rep = pos_z.to('cpu').detach().numpy() \n",
    "    adata.obsm[key_added] = SCGDL_rep\n",
    "\n",
    "    if save_loss:\n",
    "        adata.uns['SCGDL_loss'] = loss_list\n",
    "\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "adata = SCGDL_Train(adata,hidden_dims=[128, 128],num_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DGI_loss_Draw(adata) #16 dim: 1.1579; 32 dim:0.5659; 64 dim:0.6782; 128 dim: 0.7261; 256 dimï¼š1.9262; 512 dim: 2.2487"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obsm[\"SCGDL\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(adata, use_rep='SCGDL')\n",
    "# sc.pp.neighbors(adata, use_rep='STAGATE',n_neighbors=250,n_pcs=30,knn=True,method=\"umap\") \n",
    "sc.tl.umap(adata) \n",
    "sc.pl.umap(adata,color=\"Ground Truth\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = BGMM(adata,n_cluster=7,used_obsm='SCGDL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (4, 4)\n",
    "sc.pl.umap(adata, color=[\"BayesianGaussianMixture\", \"Ground Truth\"],legend_loc='on data', \n",
    "            legend_fontsize=12,legend_fontoutline=2,frameon=False, title=[\"BayesianGaussianMixture\" + ' (ARI=%.2f)'%adata.uns[\"ARI\"], \"Ground Truth\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('Torch_pyG')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b6c5b14914244c672f1ff2231c12cd4f84e9de6a7a49ed2347547bb7be8e01f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
